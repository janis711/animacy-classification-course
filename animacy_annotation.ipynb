{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jvonk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import display, HTML\n",
    "from gitma import Catma, CatmaProject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Classifier\n",
    "clf_path = 'models/animacy_clf_full.pkl'\n",
    "classifier = joblib.load(clf_path)\n",
    "\n",
    "# Load Vectorizer\n",
    "vectorizer_path = 'models/full_feature_vectorizer.pkl'\n",
    "vectorizer = joblib.load(vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "def tokenize(text):   \n",
    "    return nltk.word_tokenize(text, 'german')\n",
    "\n",
    "def make_clf_input(tokens):\n",
    "    return [[[token] for token in tokens]]\n",
    "\n",
    "# Find Offsets for tokens\n",
    "def calc_offsets(text, tokens):\n",
    "    offsets = []\n",
    "    start = 0\n",
    "    for token in tokens:\n",
    "        start = text.find(token, start)\n",
    "        end = start + len(token)\n",
    "        offsets.append((start, end))\n",
    "    return offsets\n",
    "\n",
    "# Annotate Text\n",
    "def clf_annotate(text):\n",
    "    tokens = tokenize(text)\n",
    "    features = vectorizer.transform(make_clf_input(tokens))\n",
    "    probabilities = classifier.predict_proba(features)\n",
    "    predictions = classifier.predict(features)\n",
    "    predictions = [\"belebt\" if p == 0 else \"unbelebt\" for p in predictions]\n",
    "    confidences = np.max(probabilities, axis=1)\n",
    "    return tokens, predictions, confidences\n",
    "\n",
    "def catma_annotate(text, annotations):\n",
    "    tokens = tokenize(text)\n",
    "    annotation_labels = []\n",
    "    offsets = calc_offsets(text, tokens)\n",
    "    for start, end in offsets:\n",
    "        label = 'unbelebt'\n",
    "        for annotation in annotations:\n",
    "            if start >= annotation.start_point and end <= annotation.end_point:\n",
    "                label = 'belebt'\n",
    "        annotation_labels.append(label)\n",
    "    \n",
    "    return tokens, annotation_labels\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b150558b14bf4084b16d94a609bd10e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Es war einmal ein Müller, der war arm, aber er hatte eine schöne Tochter.', description='Texte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492fc3f7548c405ca9f035c6230a2b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Annotieren', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bc5ad20f914173b78fa2489da8acfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive annotation widget\n",
    "example_text = \"Es war einmal ein Müller, der war arm, aber er hatte eine schöne Tochter.\"\n",
    "text_input = widgets.Textarea(value=example_text, \n",
    "                              description=\"Texteingabe:\", \n",
    "                              disabled=False,\n",
    "                              layout=widgets.Layout(width='50%', height='80px')\n",
    "                              )\n",
    "button = widgets.Button(description=\"Annotieren\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        tokens, labels, confidences = clf_annotate(text_input.value)\n",
    "        annotated = list(zip(tokens, labels, confidences))\n",
    "        \n",
    "        # HTML formatting: Mark animate entities (optional different colours for confidence thresholds)\n",
    "        formatted_text = \" \".join(\n",
    "            f'<span style=\"background-color: lightgreen; padding:2px; border-radius:3px;\">{token}</span>'\n",
    "            if annotation == \"belebt\" and confidence >= 0.75 else\n",
    "            f'<span style=\"background-color: yellow; padding:2px; border-radius:3px;\">{token}</span>'\n",
    "            if annotation == \"belebt\" and 0.5 <= confidence < 0.75 else token\n",
    "            for token, annotation, confidence in annotated\n",
    "        )\n",
    "\n",
    "        # # Confidence Table\n",
    "        # conficdence_table = pd.DataFrame(zip(tokens, labels, confidences), columns=['Token', 'Label', 'Confidence'])\n",
    "\n",
    "\n",
    "        display(HTML(f\"<p>{formatted_text}</p>\"))\n",
    "        # display(conficdence_table)\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(text_input, button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tagsets ...\n",
      "\tFound 2 tagset(s).\n",
      "Loading documents ...\n",
      "\tFound 1 document(s).\n",
      "Loading annotation collections ...\n",
      "\tFound 1 annotation collection(s).\n",
      "\tAnnotation collection \"1. Der Froschkönig oder der eiserne Heinrich Belebte Entitäten A2\" for document \"1. Der Froschkönig oder der eiserne Heinrich\"\n",
      "\t\tAnnotations: 216\n"
     ]
    }
   ],
   "source": [
    "# Load Catma Project\n",
    "my_project_name = 'Belebtheit_in_Mxrchen'\n",
    "\n",
    "my_project = CatmaProject(\n",
    "   projects_directory='catma',\n",
    "   project_name=my_project_name\n",
    ")\n",
    "\n",
    "# Load Annotation Collection \n",
    "ac_name = \"1. Der Froschkönig oder der eiserne Heinrich Belebte Entitäten A2\"\n",
    "annotation_collection = next((ac for ac in my_project.annotation_collections if ac.name == ac_name), None)\n",
    "\n",
    "# Get Annotations from tag name\n",
    "annotations = annotation_collection.get_annotation_by_tag(\"belebte_entität\")\n",
    "\n",
    "# Get Text from Annotation Collection\n",
    "text = annotation_collection.text.plain_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokens from text \n",
    "tokens = tokenize(text)\n",
    "\n",
    "# Get Classifier Annotations\n",
    "_,  clf_annotation_labels, _ = clf_annotate(text)\n",
    "\n",
    "# Get Catma Annotations\n",
    "_, catma_annotation_labels = catma_annotate(text, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      belebt       0.73      0.80      0.76       260\n",
      "    unbelebt       0.96      0.94      0.95      1311\n",
      "\n",
      "    accuracy                           0.92      1571\n",
      "   macro avg       0.85      0.87      0.86      1571\n",
      "weighted avg       0.92      0.92      0.92      1571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=catma_annotation_labels, y_pred=clf_annotation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html(tokens, clf_labels, catma_labels, output_file=\"annotations.html\"):\n",
    "    html_start = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <style>\n",
    "            .clf { text-decoration: underline; text-decoration-color: blue; text-decoration-thickness: 3px; }\n",
    "            .catma { text-decoration: underline; text-decoration-color: red; text-decoration-thickness: 3px; }\n",
    "            .both { text-decoration: underline; text-decoration-color: yellow; text-decoration-thickness: 3px; }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    <div class=\"legend\">\n",
    "        <span class=\"clf\">Classifier</span><br>\n",
    "        <span class=\"catma\">Catma</span><br>\n",
    "        <span class=\"both\">Both</span><br>\n",
    "        <br>\n",
    "        <br>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    html_end = \"</body></html>\"\n",
    "    \n",
    "    body_content = \"\"\n",
    "    for token, clf_label, catma_label in zip(tokens, clf_labels, catma_labels):\n",
    "        if clf_label == \"belebt\" and catma_label == \"belebt\":\n",
    "            span = f'<span class=\"both\">{token}</span>'\n",
    "        elif clf_label == \"belebt\":\n",
    "            span = f'<span class=\"clf\">{token}</span>'\n",
    "        elif catma_label == \"belebt\":\n",
    "            span = f'<span class=\"catma\">{token}</span>'\n",
    "        else:\n",
    "            span = token\n",
    "        \n",
    "        body_content += span + \" \"\n",
    "    \n",
    "    html_content = html_start + body_content + html_end\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"HTML-Datei wurde erstellt: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML-Datei wurde erstellt: annotations.html\n"
     ]
    }
   ],
   "source": [
    "generate_html(tokens, clf_annotation_labels, catma_annotation_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
